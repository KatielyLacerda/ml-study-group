# Grupo de Estudos de Machine Learning Clássico
Esse grupo de estudos tem como objetivo introduzir o assunto de Machine Learning a novos membros do DATA, 
contando com uma ajudinha da internet e tentando organizar os conteúdos da melhor forma.
Os encontros terão o formato de seminários, onde dois ou mais alunos apresentarão um tópico. Os temas abaixo são propostas e os participantes são encorajados a propor novos tópicos.

Em cada seminário, além da apresentação vamos contar com um **pequeno resumo do tema**, com referências para aula e um **jupyter notebook**. 

Por favor não usem o GPT para escrever os resumos! É uma ótima ferramenta para gerar lero-leros, mas o objetivo do grupo de estudos é entender junto os assuntos.


## Lista de Encontros
| Data | Tópico |
|------|------|
| 06/03 | [Introdução a Machine Learning](meetings/mlc01/README.md) |

## Referências
As aulas de [Patrick Winston MIT IA](https://www.youtube.com/watch?v=TjZBTDzGeGg&list=PLUl4u3cNGP63gFHB6xb-kVBiQHYe_4hSi) apresentam um panorama geral de alguns tópicos que discutiremos no grupo de estudos, com uma boa didática. Nem todos tópicos são abordados no curso de Winston, então podemos estudar com maior detalhes em [An Introduction to Statistical Learning (ISL)](https://www.statlearning.com/), que apresenta as principais ideias, conceitos matemáticos e códigos de ML. Uma ótima alternativa ao ISL é o livro [Probabilistic Machine Learning (PML)](https://probml.github.io/pml-book/book1.html). Se os conceitos apresentados no livro parecerem muito complexos (e são!), o canal [Statquest](https://www.youtube.com/@statquest) no Youtube tem vídeos destrichando temas complexos de maneira muito simples. Por fim, o canal [3Blue1Brown](https://www.youtube.com/@3blue1brown) tem bons vídeos para intuição em fundamentos de ML, além de ótima visualização para Redes Neurais. 

## Tópicos (decidiremos em encontro)
### Introdução
- Introdução a Machine Learning, Jargões de ML
### Fundamentos
- Matriz de Confusão, Sensibilidade e Especificidade, AUC e ROC
- Entropia, Informação Mútua (teoria da informação), K-Vizinhos Próximos
### Aprendizado Supervisionado
- Regressão 1: Regressão Linear e Logística
- Regressão 2: Ridge e Lasso
- Árvores 1: Árvores de Decisão, Random Forests
- Árvores 2: Bagging, Boosting
- Redes Neurais 1: MLP, Backpropagation
- Redes Neurais 2: Redes Neurais Profundas e Principais Ideias
- Máquinas de Suporte Vetorial
### Aprendizado Não-Supervisionado
- Agrupamento: Hierárquico, K-Médias
- Principal Component Analysis


